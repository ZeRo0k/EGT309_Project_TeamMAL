paths:
  cleaned_train: "/datasets/cleaned_datasets/cleaned_train_data.csv"
  model_output: "/saved_model/optimized_model.pkl"

parameters:
  target_column: "Survived"
  test_size: 0.2
  random_state: 42

# Model Type Selection
model_type: ""

# Logistic Regression Hyperparameters
logistic_regression:
  C: [0.01, 0.1, 0.5, 1.0]
  penalty: ["elasticnet"]
  solver: ["saga"]
  l1_ratio: [0.1, 0.5, 0.7]
  max_iter: [5000]

# Random Forest Hyperparameters
random_forest:
  n_estimators: [50, 100, 200] # Fewer trees for faster training and less overfitting
  max_depth: [5, 10, 15] # Lower depth for smaller datasets
  min_samples_split: [2, 5] # Smaller splits due to limited data

# Gradient Boosting Hyperparameters
gradient_boosting:
  n_estimators: [50, 100, 200] # Fewer boosting stages for smaller datasets
  max_depth: [3, 4, 5] # Lower depth to avoid overfitting
  min_samples_split: [2, 5] # Smaller splits for small datasets
  learning_rate: [0.01, 0.05, 0.1] # Lower learning rate for stable training

# Cross-Validation Settings
cross_validation:
  n_splits: 7 # More folds for stable cross-validation on smaller data
  shuffle: true
  random_state: 42
